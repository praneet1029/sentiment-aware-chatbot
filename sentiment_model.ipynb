{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s3CizGny-qlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a6ed79-411c-49fd-f5c3-f29656f0f686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn matplotlib seaborn joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "import random\n",
        "\n",
        "# Get words and labels (positive or negative)\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(documents)  # Mix it up\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AdSw6gUANAa",
        "outputId": "7438e7fc-dd9a-49c4-da88-5cc550df2375"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "all_words = FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]  # Top 2000 words\n",
        "\n",
        "def document_features(doc):\n",
        "    doc_words = set(doc)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[f'contains({word})'] = (word in doc_words)\n",
        "    return features\n",
        "\n",
        "# Apply the function to all documents\n",
        "feature_sets = [(document_features(d), c) for (d, c) in documents]\n"
      ],
      "metadata": {
        "id": "hz8qxUtOASsR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "# Split data: 80% train, 20% test\n",
        "train_set, test_set = train_test_split(feature_sets, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes model (very good for text)\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Test accuracy\n",
        "print(\"Model Accuracy:\", nltk.classify.accuracy(classifier, test_set) * 100, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GEf-XpSAYkx",
        "outputId": "41d6d482-e3a8-460c-ec13-e391223da6b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 76.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_true = [label for (_, label) in test_set]\n",
        "y_pred = [classifier.classify(feats) for (feats, _) in test_set]\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(\"\\nPerformance Report:\")\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Gd3pMIDAc-_",
        "outputId": "20980517-e0fd-4290-f50c-6367614f5e25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[178  33]\n",
            " [ 61 128]]\n",
            "\n",
            "Performance Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.74      0.84      0.79       211\n",
            "         pos       0.80      0.68      0.73       189\n",
            "\n",
            "    accuracy                           0.77       400\n",
            "   macro avg       0.77      0.76      0.76       400\n",
            "weighted avg       0.77      0.77      0.76       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(classifier, \"saved_model.pkl\")\n",
        "joblib.dump(word_features, \"word_features.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iGjInuaAhZ9",
        "outputId": "fc245b4a-07d6-47a0-c279-3c18b04071e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['word_features.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(text):\n",
        "    words = text.lower().split()\n",
        "    feats = document_features(words)\n",
        "    sentiment = classifier.classify(feats)\n",
        "\n",
        "    if sentiment == 'pos':\n",
        "        return \"ðŸ˜Š I'm glad to hear that! How else can I help you?\"\n",
        "    elif sentiment == 'neg':\n",
        "        return \"ðŸ˜Ÿ I'm sorry to hear that. Can you tell me more?\"\n",
        "    else:\n",
        "        return \"ðŸ¤” Hmm. How can I help you today?\"\n",
        "\n",
        "# Try chatting!\n",
        "user_input = input(\"You: \")\n",
        "print(\"Bot:\", chatbot_response(user_input))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iJwdHemApGk",
        "outputId": "28bcdefc-bea4-4e01-cdb6-197f0ca62c4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: I HAD A BAD DAY\n",
            "Bot: ðŸ˜Ÿ I'm sorry to hear that. Can you tell me more?\n"
          ]
        }
      ]
    }
  ]
}